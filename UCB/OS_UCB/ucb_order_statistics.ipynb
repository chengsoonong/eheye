{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from UCB_discrete import UCB_os_gau, UCB_os_exp, UCB1_os, UCB_os_comb\n",
    "from collections import defaultdict\n",
    "import Environment\n",
    "from Environment import AbsGau, Exp, Comb\n",
    "from SimulatedGames import simulate\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCB for order statistics\n",
    "\n",
    "This notebook is designed to show the idea using order statistics to design UCB policies works empirically. The experiment is designed on simulated data, for two special reward distributions proved by [notes](https://github.com/chengsoonong/eheye/tree/master/writing/QuantUCB_orderstat): \n",
    "\n",
    "(1) Absolute value of center Gaussian rewards  \n",
    "(2) Exponential rewards  \n",
    "(3) Arbtrary distributions (combing 1 and 2)\n",
    "\n",
    "For each case, we show the results for both estiamted parameter and true parameter.\n",
    "\n",
    "Settings: 3 independent arms, 10000 rounds with 50 indepenent experiments. Evaluated by \n",
    "a. expected sub-optimal draws.\n",
    "b. the percent of best arm selected. \n",
    "\n",
    "Policy (Empirical policy): In round t+1, select the arm with index, \n",
    "$$argmax_{i \\in \\mathcal{K}} \\hat{m}_{i, T_i(t)} + \\beta(\\sqrt{2v_t \\varepsilon} + 2 \\varepsilon \\sqrt{v_t/T_i(t)})$$\n",
    "\n",
    "where $\\hat{m}_{i, T_i(t)}$ is the empirical median for arm i at the round t, $\\varepsilon = \\alpha \\log t$, $v_t$ depends on reward distributions. $T_i(t)$ is the number of times arm i has been played until round t. \n",
    "\n",
    "We fix the parameters $\\alpha, \\beta$ in this notebook, see [here](https://github.com/chengsoonong/eheye/blob/master/UCB/OS_UCB/ucb_os_hyperparameter_tuning_outliers_testing.ipynb) for experiments on tuning parameters, [here](https://github.com/chengsoonong/eheye/blob/master/UCB/OS_UCB/Variance_Sensitiveness_test.ipynb) for experiments test the policy senstivity for different variance of reward distribution, [here](https://github.com/chengsoonong/eheye/blob/master/UCB/OS_UCB/Sanity_test.ipynb) for some sanity test of our policy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "\n",
    "num_rounds = 1000\n",
    "num_exper = 50\n",
    "num_arms = 3\n",
    "\n",
    "# environment\n",
    "\n",
    "environments = {#AbsGau: [0.7, 0.8, 0.9], \n",
    "                #Exp: [0.7, 1, 1.2],\n",
    "                Comb: [0.7, 0.7, 1]\n",
    "               }\n",
    "\n",
    "rewards_env, medians = Environment.setup_env(num_arms, environments)\n",
    "\n",
    "# policy\n",
    "\n",
    "policy = {'AbsGau': UCB_os_gau,\n",
    "          'Exp': UCB_os_exp,\n",
    "          'Comb': UCB_os_comb\n",
    "         }\n",
    "# hyper-parameters for policy\n",
    "\n",
    "hyperpara_list = [[1, 0.2]]\n",
    "\n",
    "evaluation = ['sd', 'r', 'bd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comb_50_1000True[1, 0.2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4746555609aa4afb973d56d5d3bcde21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Running', max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comb_50_1000False[1, 0.2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590d4aef70df454183ad90e90e89996d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Running', max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = defaultdict(dict)\n",
    "\n",
    "for key in rewards_env.keys():\n",
    "    for hyperpara in hyperpara_list:\n",
    "        for est_var in [True, False]:\n",
    "            name = key + '_' + str(num_exper) + '_' + str(num_rounds) \n",
    "            subname = str(est_var) + str(hyperpara)\n",
    "            print(name + subname)\n",
    "            p = IntProgress(max = num_exper)\n",
    "            p.description = 'Running'\n",
    "            display(p)\n",
    "            results[name][subname], results[name]['bound'] = \\\n",
    "                    simulate(rewards_env[key], medians[key], policy[key], num_exper, num_rounds, est_var, hyperpara, evaluation, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('os_saving.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comb_50_1000UCB1_[1, 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c14a35714545b889c18074b4d588c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Running', max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hyperpara = [1, 1]\n",
    "est_var = False\n",
    "\n",
    "for key in rewards_env.keys():\n",
    "    name = key + '_' + str(num_exper) + '_' + str(num_rounds)\n",
    "    subname = 'UCB1_' + str(hyperpara)\n",
    "    print(name + subname)\n",
    "    p = IntProgress(max = num_exper)\n",
    "    p.description = 'Running'\n",
    "    display(p)\n",
    "    results[name][subname], bounds= simulate(rewards_env[key], medians[key], UCB1_os, num_exper, num_rounds, est_var, hyperpara, evaluation, p)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "saving = results\n",
    "\n",
    "with open('os_saving.pickle', 'wb') as handle:\n",
    "    pickle.dump(saving, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
