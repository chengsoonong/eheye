{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import os\n",
    "import matplotlib.colors as mc\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distros = ['mix', 'gau 1', 'gau 2', 'exp']\n",
    "stepsizes = ['const', '2/sqrt_k', '0.002/sqrt_k']\n",
    "\n",
    "tau_vals = [0.1, 0.3, 0.5, 0.9, 0.99]\n",
    "N_g = 12 # N_generation\n",
    "N_s = 10 # N_shuffle\n",
    "\n",
    "N_q = len(tau_vals)\n",
    "\n",
    "c_Norm = colors.Normalize(vmin=0, vmax=1)\n",
    "scalarMap = cmx.ScalarMappable(norm=c_Norm, cmap=plt.get_cmap('cool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_settings(distro_lst, datasize_lst, stepsize_lst):\n",
    "    len_lst = [len(distro_lst), len(datasize_lst), len(stepsize_lst)]\n",
    "    if len_lst.count(1) != len(len_lst)-1: raise Exception(\"Setting inputs are wrong!\")\n",
    "    \n",
    "    N_settings = max((len_lst))\n",
    "    setting_lst = []\n",
    "    for lst in [distro_lst, datasize_lst, stepsize_lst]:\n",
    "        if len(lst)==1: \n",
    "            lst = lst*N_settings\n",
    "        setting_lst.append(lst)\n",
    "    return np.asarray(setting_lst).T, len(stepsize_lst)>1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_dt(distro, datasize):\n",
    "#     return np.ones(size)\n",
    "    if distro == 'gau 1':\n",
    "        return np.random.normal(2, 18, datasize)\n",
    "    elif distro == 'gau 2':\n",
    "        return np.random.normal(0, 0.001, datasize)\n",
    "    elif distro == 'mix':\n",
    "        # mean: -1.3\n",
    "        # std: 30.779035604224564\n",
    "        # var: 947.3490327261234\n",
    "        mix_lst = np.zeros(datasize)\n",
    "        sizes = np.array([0.3, 0.2, 0.1, 0.15, 0.25])\n",
    "        mixtures = [(2,7), (0,0.7), (36, 26), (5,77), (-77,7)]\n",
    "        acc_sizes = [sum(sizes[:i+1]) for i in range(len(sizes))]\n",
    "\n",
    "        for d_idx in range(datasize):\n",
    "            rdn = np.random.uniform(0,1)\n",
    "            mix_id = 0\n",
    "            for m_id in acc_sizes:\n",
    "                if rdn > m_id:\n",
    "                    mix_id += 1\n",
    "                else:break\n",
    "            data_point = np.random.normal(mixtures[mix_id][0], mixtures[mix_id][1])\n",
    "            mix_lst[d_idx] = data_point\n",
    "        return mix_lst\n",
    "    elif distro == 'exp':\n",
    "        return np.random.exponential(scale=1, size=datasize)\n",
    "    else: raise Exception(\"distribution doesn't work!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(distro, datasize, g_test):\n",
    "    if g_test:\n",
    "        dataset = np.zeros((N_g, datasize))\n",
    "        for i in range(N_g):\n",
    "            dataset[i] = get_one_dt(distro, datasize)\n",
    "    else:\n",
    "        dataset = get_one_dt(distro, datasize)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_true(distro, tau_lst):\n",
    "    if tau_lst == tau_vals:\n",
    "        if distro=='gau 1':\n",
    "            return np.asarray([-21.06792817980280840537, \n",
    "                              -7.43920922874473411269,\n",
    "                              2,\n",
    "                              25.06792817980280840537,\n",
    "                              43.87426173273513981594])\n",
    "        elif distro=='gau 2':\n",
    "            return np.asarray([-0.001281551565544600466965,\n",
    "                              -5.244005127080407840383E-4,\n",
    "                              0,\n",
    "                              0.001281551565544600466965,\n",
    "                              0.002326347874040841100886])\n",
    "        elif distro=='mix':\n",
    "            # sampled from 100000000 datapoints\n",
    "            return np.asarray([-80.28496182,\n",
    "                               -29.02324254,\n",
    "                               -0.36011575,\n",
    "                               36.69268923,\n",
    "                               120.7676231])\n",
    "        elif distro=='exp':\n",
    "            return np.asarray([0.1053605156578263012275,\n",
    "                              0.3566749439387323789126,\n",
    "                              0.6931471805599453094172,\n",
    "                              2.302585092994045684018,\n",
    "                              4.605170185988091368036])\n",
    "    raise Exception('tau_lst should be tau_vals')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_batch(dataset, tau_lst):\n",
    "    if len(dataset.shape) != 1:\n",
    "        raise Exception('Dataset for q_batch calculation of wrong shape: ' + str(dataset.shape))\n",
    "        \n",
    "    q_batch = np.zeros(len(tau_lst))\n",
    "    for i, tau in enumerate(tau_lst):\n",
    "        q_batch[i] = np.percentile(dataset, tau*100)\n",
    "    return q_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_batches(dataset, tau_lst):\n",
    "    # g_test = False\n",
    "    if len(dataset.shape) == 1: \n",
    "        return get_q_batch(dataset, tau_lst)\n",
    "    else:\n",
    "        q_batches = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "        for i in range(q_batches.shape[0]):\n",
    "            q_batches[i] = get_q_batch(dataset[i], tau_lst)\n",
    "    return q_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stepsize(k, stepsize):\n",
    "    if stepsize=='const':\n",
    "        return 1\n",
    "    elif stepsize=='2/sqrt_k':\n",
    "        return 2/math.sqrt(k)\n",
    "    elif stepsize=='0.002/sqrt_k':\n",
    "        return 0.002/math.sqrt(k)\n",
    "    raise Exception('stepsize parameter is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procs(dataset, step_size, tau_lst):\n",
    "    if len(dataset.shape)!= 1: \n",
    "        raise Exception('Dataset for get_procs() of wrong shape:' + str(dataset.shape)+ ', should be 1d array')\n",
    "        \n",
    "    procs = np.zeros((len(tau_lst), dataset.shape[0]))\n",
    "    q = 0\n",
    "    for idx, tau in enumerate(tau_lst):\n",
    "        q_sgd_proc = procs[idx]\n",
    "        # change stepsize\n",
    "        if step_size != 'frugal':\n",
    "            for k, x in enumerate(dataset):\n",
    "                alpha = set_stepsize(k+1, step_size)\n",
    "                if x > q:\n",
    "                    q += alpha*tau\n",
    "                else:\n",
    "                    q -= alpha*(1-tau)\n",
    "                q_sgd_proc[k] = q\n",
    "        \n",
    "        # frugal\n",
    "        else:\n",
    "            rdn_lst = np.random.uniform(0,1, dataset.shape[0])\n",
    "            for k, x in enumerate(dataset):\n",
    "                rdn = rdn_lst[k]\n",
    "                if x > q and rdn > 1-tau:\n",
    "                    q += 1\n",
    "                elif x < q and rdn > tau:\n",
    "                    q -= 1\n",
    "                q_sgd_proc[k] = q\n",
    "    return procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(procs):\n",
    "    if len(procs.shape)!=2:raise Exception('Procs of wrong shape:' + str(procs.shape)+ ', should be 2d array')\n",
    "    return procs[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_ests(dataset, step_size, tau_lst):\n",
    "\n",
    "    if len(dataset.shape)>2:\n",
    "        raise Exception('Dataset for q_est calculation of wrong shape:' + str(dataset.shape)+ ', should be 1d or 2d array')\n",
    "    if len(dataset.shape)==1:\n",
    "        procs = get_procs(dataset, step_size, tau_lst)\n",
    "        res = get_res(procs)\n",
    "    else:\n",
    "        res = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "        procs = np.zeros((dataset.shape[0], len(tau_lst), dataset.shape[1]))\n",
    "        for idx, dt in enumerate(dataset):\n",
    "            procs[idx] = get_procs(dt, step_size, tau_lst)\n",
    "            res[idx] = get_res(procs[idx])\n",
    "    return res, procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_dataset('gau 1', 1000, g_test=True) * 50 - 200\n",
    "# print(dataset.shape)\n",
    "\n",
    "# # proc1 = get_procs(dataset, 'const', tau_vals)\n",
    "# ## res1 = get_res(proc1)\n",
    "# # proc2 = get_procs(dataset, 'frugal', tau_vals)\n",
    "# # plt.plot(proc1.T)\n",
    "# # plt.plot(proc2.T)\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# res, proc = get_q_ests(dataset, 'const', tau_vals)\n",
    "# print(res)\n",
    "# print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_sgd_compare(distro_lst, datasize_lst, stepsize_lst, \n",
    "                         g_test=False, s_test=False, tau_lst=tau_vals):\n",
    "    \n",
    "    if g_test and s_test: raise Exception(\"g_test and s_test can't both be true\")\n",
    "    \n",
    "    # generate different settings\n",
    "    setting_lst, is_stepsize = get_settings(distro_lst, datasize_lst, stepsize_lst,)\n",
    "    print (setting_lst)\n",
    "    # if only stepsize changes, generate dataset and q_batches\n",
    "    dataset, q_batches = 0, 0\n",
    "    if is_stepsize:\n",
    "        dataset = get_dataset(distro_lst[0], datasize_lst[0], g_test)\n",
    "        q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "    # for each setting = [distro, datasize, stepsize]\n",
    "    for idx, setting in enumerate(setting_lst):\n",
    "        # generate all the data\n",
    "        distro, datasize, stepsize = setting[0], int(setting[1]), setting[2]\n",
    "        q_true = get_q_true(distro, tau_lst)\n",
    "        print (q_true)\n",
    "        if not is_stepsize:\n",
    "            dataset = get_dataset(distro, datasize, g_test)\n",
    "            q_batches = get_q_batches(dataset, tau_lst)\n",
    "        if s_test:\n",
    "            shuffled_dt = np.zeros((N_s, datasize))\n",
    "            for i in range(N_s):\n",
    "                np.random.shuffle(dataset)\n",
    "                shuffled_dt[i] = dataset\n",
    "            dataset = shuffled_dt\n",
    "        q_est_res, q_est_proc = get_q_ests(dataset, stepsize, tau_lst)\n",
    "        \n",
    "#         # generate charts and tables?\n",
    "#         name = get_name(distro, datasize, stepsize, tau_list, g_test, s_test)\n",
    "#         charts = get_charts(tau_lst, q_batches, q_sgd_res, q_sgd_proc, name)\n",
    "# #         tables = get_tables(tau_lst, q_batches, q_sgd_res, q_sgd_proc, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "### Always have $q_k = x$ for each x in the data stream\n",
    "\n",
    "When $x - q_k > 0$, we have $l(q_k) = \\tau(x-q_k)$:\n",
    "\\begin{align}\n",
    "q_{k+1} & = q_k - \\frac{l(q_k)}{l'(q_k)} \\\\\n",
    "        & = q_k - \\frac{\\tau(x-q_k)}{-\\tau} \\\\\n",
    "        & = q_k - (- x + q_k) \\\\\n",
    "        & = x\n",
    "\\end{align}\n",
    "\n",
    "Same happens when $x - q_k < 0$\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mix' '100' '2/sqrt_k']\n",
      " ['mix' '150' '2/sqrt_k']\n",
      " ['mix' '200' '2/sqrt_k']]\n",
      "[-80.28496182 -29.02324254  -0.36011575  36.69268923 120.7676231 ]\n",
      "[-80.28496182 -29.02324254  -0.36011575  36.69268923 120.7676231 ]\n",
      "[-80.28496182 -29.02324254  -0.36011575  36.69268923 120.7676231 ]\n"
     ]
    }
   ],
   "source": [
    "quantile_sgd_compare(distro_lst=['mix'], \n",
    "                     datasize_lst=[100, 150, 200], \n",
    "                     stepsize_lst=['2/sqrt_k'], \n",
    "                     g_test=False,\n",
    "                     s_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
