{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from Distro_generation import get_dataset, get_q_batches, get_q_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "distros = ['mix', 'gau_1', 'gau_2', 'exp']\n",
    "stepsizes = ['const', '2_div_sqrt_k', '0.002_div_sqrt_k']\n",
    "\n",
    "tau_vals = [0.1, 0.3, 0.5, 0.9, 0.99]\n",
    "N_g = 12 # N_generation\n",
    "N_s = 10 # N_shuffle\n",
    "\n",
    "N_q = len(tau_vals)\n",
    "\n",
    "# c_Norm = colors.Normalize(vmin=0, vmax=1)\n",
    "# scalarMap = cmx.ScalarMappable(norm=c_Norm, cmap=plt.get_cmap('cool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_fd = 'Experiment_results/'\n",
    "fd_lst = ['Frugal_SGD', 'SGD']\n",
    "for fd in fd_lst:\n",
    "    if not os.path.exists(main_fd+fd):\n",
    "        os.makedirs(main_fd+fd)\n",
    "        \n",
    "sgd_lst = ['distro', 'data_size', 'step_size', 'data_sequence']        \n",
    "for fd in sgd_lst:\n",
    "    fd_name = main_fd+'SGD/'+fd\n",
    "    if not os.path.exists(fd_name):\n",
    "        os.makedirs(fd_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_settings(distro_lst, datasize_lst, stepsize_lst):\n",
    "    len_lst = [len(distro_lst), len(datasize_lst), len(stepsize_lst)]\n",
    "    if len_lst.count(1) != len(len_lst)-1: raise Exception(\"Setting inputs are wrong!\")\n",
    "    \n",
    "    N_settings = max((len_lst))\n",
    "    setting_lst = []\n",
    "    for lst in [distro_lst, datasize_lst, stepsize_lst]:\n",
    "        if len(lst)==1: \n",
    "            lst = lst*N_settings\n",
    "        setting_lst.append(lst)\n",
    "        \n",
    "    changed_setting = None\n",
    "    change_lst = ['distro', 'data_size', 'step_size']\n",
    "    for idx, l in enumerate(len_lst):\n",
    "        if l>1: changed_setting = change_lst[idx]\n",
    "    return np.asarray(setting_lst).T, changed_setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stepsize(k, stepsize, length):\n",
    "    if stepsize=='const':\n",
    "        return 1 * np.ones(length)\n",
    "    elif stepsize=='2_div_sqrt_k':\n",
    "        return 2/math.sqrt(k)* np.ones(length)\n",
    "    elif stepsize=='0.002_div_sqrt_k':\n",
    "        return 0.002/math.sqrt(k) * np.ones(length)\n",
    "    raise Exception('stepsize parameter is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procs(dataset, step_size, tau_lst):\n",
    "    update_size = 200\n",
    "    proc = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "    q_pre, q_arr = np.zeros(len(tau_lst)), np.zeros(len(tau_lst))\n",
    "    alpha_adaptation = np.ones(len(tau_lst))\n",
    "\n",
    "    for k, x in enumerate(dataset):          \n",
    "        if k % update_size == 0 and k >0:\n",
    "#             print (k,q_arr-q_pre)\n",
    "            update_var = update_stepsize(alpha_arr, q_arr-q_pre, step_size, update_size)\n",
    "#             print ('update_var', update_var)\n",
    "            alpha_adaptation = alpha_adaptation * update_var\n",
    "#             print ('alpha_adaptation', alpha_adaptation)\n",
    "            q_pre = [i for i in q_arr]\n",
    "        if step_size != 'frugal': \n",
    "            alpha_arr = set_stepsize(k+1, step_size, len(tau_lst))* alpha_adaptation\n",
    "#             if k % update_size == 0: print('alpha_arr', alpha_arr)\n",
    "        for i, q in enumerate(q_arr):\n",
    "            tau = tau_lst[i]\n",
    "            alpha = alpha_arr[i]\n",
    "            if step_size != 'frugal':\n",
    "                q = sgd(q, x, tau, alpha)\n",
    "            else: \n",
    "                q = frugal(q, x, tau)\n",
    "            q_arr[i] = q\n",
    "        proc[k] = q_arr\n",
    "#     print (alpha_arr)\n",
    "    return proc.T\n",
    "\n",
    "def update_stepsize(alpha_arr, diff, step_size, update_size):\n",
    "    update_var = np.ones(len(diff))\n",
    "    for i, a in enumerate(alpha_arr):\n",
    "        d = diff[i]\n",
    "        if a * update_size * 0.25 < abs(d): update_var[i] = 2\n",
    "        elif a * update_size * 0.02 > abs(d): update_var[i] = 1/2\n",
    "#     print ('step_size', update_var)\n",
    "    return update_var\n",
    "    \n",
    "def sgd(q, x, tau, alpha):\n",
    "    if x > q:\n",
    "        q = q + alpha*tau\n",
    "    else:\n",
    "        q = q - alpha*(1-tau)  \n",
    "    return q\n",
    "    \n",
    "def frugal(q, x, tau):\n",
    "    rdn = np.random.uniform()\n",
    "    if x > q and rdn > 1-tau:\n",
    "        q += 1\n",
    "    elif x < q and rdn > tau:\n",
    "        q -= 1\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(procs):\n",
    "    if len(procs.shape)!=2:raise Exception('Procs of wrong shape:' + str(procs.shape)+ ', should be 2d array')\n",
    "    return procs[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_ests(dataset, step_size, tau_lst):\n",
    "\n",
    "    if len(dataset.shape)>2:\n",
    "        raise Exception('Dataset for q_est calculation of wrong shape:' + str(dataset.shape)+ ', should be 1d or 2d array')\n",
    "    if len(dataset.shape)==1:\n",
    "        procs = get_procs(dataset, step_size, tau_lst)\n",
    "        res = get_res(procs)\n",
    "    else:\n",
    "        res = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "        procs = np.zeros((dataset.shape[0], len(tau_lst), dataset.shape[1]))\n",
    "        for idx, dt in enumerate(dataset):\n",
    "            procs[idx] = get_procs(dt, step_size, tau_lst)\n",
    "            res[idx] = get_res(procs[idx])\n",
    "    return res, procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_e(true, batches, est):\n",
    "    upper = est - batches\n",
    "    bottom = true - batches\n",
    "    return (upper/bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, filename, setting=None):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        if setting is not None: outfile.write('# Setting: {0}\\n'.format(setting))\n",
    "        if len(data.shape) == 1: data = data.reshape(-1, 1)\n",
    "        outfile.write('# Array shape: {0}\\n \\n'.format(data.shape))\n",
    "\n",
    "        for data_slice in data:\n",
    "            np.savetxt(outfile, data_slice, fmt='%-15.8g')\n",
    "            outfile.write('\\n')\n",
    "\n",
    "\n",
    "def write_data_overview(category, setting, tau_lst, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(\"Tested on \"+category+\": \"+str(setting)+\"\\n\") \n",
    "        f.write(str(tau_lst))\n",
    "    \n",
    "# write_data_overview('ca', 'se', tau_vals, \"try.txt\")\n",
    "    \n",
    "def save_data(foldername, file_name, tau_lst, data_dict):\n",
    "    print (\"save data in folder\", foldername)\n",
    "    pathlib.Path(foldername).mkdir(parents=True, exist_ok=True) \n",
    "    category, setting = file_name[0], file_name[1]    \n",
    "    write_data_overview(category, setting, tau_lst, foldername+str(setting)+\"_\"+\"overview.txt\")\n",
    "\n",
    "    for data_name in data_dict:\n",
    "        print (foldername+str(setting)+\"_\"+data_name+'.txt')\n",
    "        write_data(data_dict[data_name], foldername+str(setting)+\"_\"+data_name+'.txt')\n",
    "        \n",
    "    return\n",
    "\n",
    "# save_data(np.random.uniform(0, 1, 100), 'Experiment_results/Adaptive_stepsize/distro/mix_overview.txt')\n",
    "# save_data('', ('C', 'S'), tau_vals, {'dataset': np.reshape(np.random.uniform(0, 4, 100), (2, 5, 10))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(changed_setting, distro, datasize, stepsize, s_test):\n",
    "#     print(changed_setting)\n",
    "#     if s_test:\n",
    "#         return ('Shuffle', True)\n",
    "    if changed_setting=='distro':\n",
    "        return ('Distribution', distro)\n",
    "    elif changed_setting=='data_size':\n",
    "        return ('Data size', datasize)\n",
    "    elif changed_setting=='step_size':\n",
    "        return ('Step size', stepsize)\n",
    "    else: raise Exception ('Cannot get file name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffled_dataset(dataset, datasize, s_test):\n",
    "    if not s_test: return dataset\n",
    "    \n",
    "    shuffled_dt = np.zeros((N_s, datasize))\n",
    "    for i in range(N_s):\n",
    "        np.random.shuffle(dataset)\n",
    "        shuffled_dt[i] = dataset\n",
    "    dataset = shuffled_dt\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_sgd_compare(folder_name, distro_lst, datasize_lst, stepsize_lst, \n",
    "                         g_test=False, s_test=False, tau_lst=tau_vals, \n",
    "                        ):\n",
    "    \n",
    "    if g_test and s_test: raise Exception(\"g_test and s_test can't both be true\")\n",
    "    \n",
    "    # generate different settings\n",
    "    setting_lst, changed_setting = get_settings(distro_lst, datasize_lst, stepsize_lst,)\n",
    "    print (setting_lst)\n",
    "    \n",
    "    # if only stepsize changes, generate dataset and q_batches\n",
    "    dataset, q_batches = 0, 0\n",
    "    if len(distro_lst)==1 and len(datasize_lst)==1:\n",
    "        dataset = get_dataset(distro_lst[0], datasize_lst[0], g_test)\n",
    "        q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "    # for each setting = [distro, datasize, stepsize]\n",
    "    for idx, setting in enumerate(setting_lst):\n",
    "        \n",
    "        # generate all the data\n",
    "        distro, datasize, stepsize = setting[0], int(setting[1]), setting[2]\n",
    "        q_true = get_q_true(distro, tau_lst)\n",
    "        if len(distro_lst)!=1 or len(datasize_lst)!=1:\n",
    "            dataset = get_dataset(distro, datasize, g_test)\n",
    "            q_batches = get_q_batches(dataset, tau_lst)\n",
    "        if not s_test: \n",
    "            dataset = get_shuffled_dataset(dataset, datasize, s_test)\n",
    "        q_est_res, q_est_proc = get_q_ests(dataset, stepsize, tau_lst)\n",
    "        E = get_normalized_e(q_true, q_batches, q_est_res)\n",
    "        \n",
    "        data_dict = {\n",
    "            'q_true': q_true,\n",
    "            'q_batches': q_batches,\n",
    "            'q_est_res': q_est_res,\n",
    "            'q_est_proc': q_est_proc,\n",
    "            'E': E\n",
    "        }\n",
    "#         print(E)\n",
    "#         # generate charts and tables?\n",
    "        file_name = get_file_name(changed_setting, distro, datasize, stepsize, s_test)\n",
    "        save_data(folder_name, file_name, tau_lst, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_lst = ['data_size', 'distro', ]        \n",
    "\n",
    "def all_sgd_comparisons(sgd_lst, root_folder='SGD'):\n",
    "    for t in sgd_lst:\n",
    "        print (t)\n",
    "        folder_name = \"Experiment_results/{}/{}/\".format(root_folder, t)\n",
    "        if t=='distro':\n",
    "            quantile_sgd_compare(folder_name, distros, [1000], ['const'], True)\n",
    "        elif t=='data_size':\n",
    "            quantile_sgd_compare(folder_name, ['gau_2'], [1000, 10000], ['const'], True)\n",
    "        elif t=='step_size':\n",
    "            quantile_sgd_compare(folder_name, ['gau_1'], [1000], stepsizes, True)\n",
    "        elif t=='data_sequence':\n",
    "            quantile_sgd_compare(folder_name, ['gau_1', 'gau_1'], [1000], ['const'], False, True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size\n",
      "[['gau_2' '1000' 'const']\n",
      " ['gau_2' '10000' 'const']]\n",
      "save data folder name Experiment_results/SGD/data_size/\n",
      "Experiment_results/SGD/data_size/1000_q_true.txt\n",
      "Experiment_results/SGD/data_size/1000_q_batches.txt\n",
      "Experiment_results/SGD/data_size/1000_q_est_res.txt\n",
      "Experiment_results/SGD/data_size/1000_q_est_proc.txt\n",
      "Experiment_results/SGD/data_size/1000_E.txt\n",
      "save data folder name Experiment_results/SGD/data_size/\n",
      "Experiment_results/SGD/data_size/10000_q_true.txt\n",
      "Experiment_results/SGD/data_size/10000_q_batches.txt\n",
      "Experiment_results/SGD/data_size/10000_q_est_res.txt\n",
      "Experiment_results/SGD/data_size/10000_q_est_proc.txt\n",
      "Experiment_results/SGD/data_size/10000_E.txt\n",
      "distro\n",
      "[['mix' '1000' 'const']\n",
      " ['gau_1' '1000' 'const']\n",
      " ['gau_2' '1000' 'const']\n",
      " ['exp' '1000' 'const']]\n",
      "save data folder name Experiment_results/SGD/distro/\n",
      "Experiment_results/SGD/distro/mix_q_true.txt\n",
      "Experiment_results/SGD/distro/mix_q_batches.txt\n",
      "Experiment_results/SGD/distro/mix_q_est_res.txt\n",
      "Experiment_results/SGD/distro/mix_q_est_proc.txt\n",
      "Experiment_results/SGD/distro/mix_E.txt\n",
      "save data folder name Experiment_results/SGD/distro/\n",
      "Experiment_results/SGD/distro/gau_1_q_true.txt\n",
      "Experiment_results/SGD/distro/gau_1_q_batches.txt\n",
      "Experiment_results/SGD/distro/gau_1_q_est_res.txt\n",
      "Experiment_results/SGD/distro/gau_1_q_est_proc.txt\n",
      "Experiment_results/SGD/distro/gau_1_E.txt\n",
      "save data folder name Experiment_results/SGD/distro/\n",
      "Experiment_results/SGD/distro/gau_2_q_true.txt\n",
      "Experiment_results/SGD/distro/gau_2_q_batches.txt\n",
      "Experiment_results/SGD/distro/gau_2_q_est_res.txt\n",
      "Experiment_results/SGD/distro/gau_2_q_est_proc.txt\n",
      "Experiment_results/SGD/distro/gau_2_E.txt\n",
      "save data folder name Experiment_results/SGD/distro/\n",
      "Experiment_results/SGD/distro/exp_q_true.txt\n",
      "Experiment_results/SGD/distro/exp_q_batches.txt\n",
      "Experiment_results/SGD/distro/exp_q_est_res.txt\n",
      "Experiment_results/SGD/distro/exp_q_est_proc.txt\n",
      "Experiment_results/SGD/distro/exp_E.txt\n"
     ]
    }
   ],
   "source": [
    "# Run all functions\n",
    "all_sgd_comparisons(sgd_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sgd_frugal_compare(distro_lst, datasize, tau_lst=tau_vals):\n",
    "#     #distro changes, use the biggest datasize, do not shuffle\n",
    "#     for distro in distro_lst:\n",
    "#         q_true = get_q_true(distro, tau_lst)\n",
    "#         dataset = get_dataset(distro, datasize, False)\n",
    "#         q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "#         sgd_res, sgd_proc = get_q_ests(dataset, 'const', tau_lst)\n",
    "        \n",
    "#         N_frugal = 20\n",
    "#         frugal_res = np.zeros((N_frugal, len(tau_lst)))\n",
    "#         frugal_proc = np.zeros((N_frugal, len(tau_lst), datasize))\n",
    "#         for i in range(N_frugal):\n",
    "#             frugal_res[i], frugal_proc[i] = get_q_ests(dataset, 'frugal', tau_lst)\n",
    "        \n",
    "#         ax_name = 'Tested on '+distro+' distritbution with '+str(datasize)+' data points'\n",
    "#         fig, lgd = plot_procs(ax_name, tau_vals, q_true, frugal_proc, sgd_proc)\n",
    "#         title = fig.suptitle('Quantile Estimation: Frugal vs SGD')\n",
    "\n",
    "#         fd = \"Experiment_results/Frugal_SGD/\"\n",
    "#         plt.savefig(fd+distro+'.png', bbox_extra_artists=(lgd, title), bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "# sgd_frugal_compare(distros, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "### Always have $q_k = x$ for each x in the data stream\n",
    "\n",
    "When $x - q_k > 0$, we have $l(q_k) = \\tau(x-q_k)$:\n",
    "\\begin{align}\n",
    "q_{k+1} & = q_k - \\frac{l(q_k)}{l'(q_k)} \\\\\n",
    "        & = q_k - \\frac{\\tau(x-q_k)}{-\\tau} \\\\\n",
    "        & = q_k - (- x + q_k) \\\\\n",
    "        & = x\n",
    "\\end{align}\n",
    "\n",
    "Same happens when $x - q_k < 0$\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_results/SGD/step_size/const_\n",
      "Experiment_results/SGD/step_size/2_div_sqrt_k_\n",
      "Experiment_results/SGD/step_size/0.002_div_sqrt_k_\n",
      "Experiment_results/SGD/distro/gau_1_\n",
      "Experiment_results/SGD/distro/mix_\n",
      "Experiment_results/SGD/distro/gau_2_\n",
      "Experiment_results/SGD/distro/exp_\n",
      "Experiment_results/SGD/data_size/100_\n",
      "Experiment_results/SGD/data_size/2000_\n",
      "Experiment_results/SGD/data_size/10000_\n",
      "Experiment_results/SGD/data_size/1000_\n",
      "Experiment_results/SGD/data_size/100000_\n",
      "Experiment_results/SGD/data_sequence/True_\n"
     ]
    }
   ],
   "source": [
    "from Plot import plot_charts\n",
    "plot_charts(\"Experiment_results/SGD/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
