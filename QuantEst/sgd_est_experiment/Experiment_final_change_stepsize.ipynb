{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import io, os, sys, types\n",
    "# from IPython import get_ipython\n",
    "# from nbformat import read\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# import matplotlib.cm as cmx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distros = ['mix', 'gau_1', 'gau_2', 'exp']\n",
    "stepsizes = ['const', '2_div_sqrt_k', '0.002_div_sqrt_k']\n",
    "\n",
    "tau_vals = [0.1, 0.3, 0.5, 0.9, 0.99]\n",
    "N_g = 12 # N_generation\n",
    "N_s = 10 # N_shuffle\n",
    "\n",
    "N_q = len(tau_vals)\n",
    "\n",
    "# c_Norm = colors.Normalize(vmin=0, vmax=1)\n",
    "# scalarMap = cmx.ScalarMappable(norm=c_Norm, cmap=plt.get_cmap('cool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_fd = 'Experiment_results/'\n",
    "fd_lst = ['Frugal_SGD', 'SGD']\n",
    "for fd in fd_lst:\n",
    "    if not os.path.exists(main_fd+fd):\n",
    "        os.makedirs(main_fd+fd)\n",
    "        \n",
    "sgd_lst = ['distro', 'data_size', 'step_size', 'data_sequence']        \n",
    "for fd in sgd_lst:\n",
    "    fd_name = main_fd+'SGD/'+fd\n",
    "    if not os.path.exists(fd_name):\n",
    "        os.makedirs(fd_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_settings(distro_lst, datasize_lst, stepsize_lst):\n",
    "    len_lst = [len(distro_lst), len(datasize_lst), len(stepsize_lst)]\n",
    "    if len_lst.count(1) != len(len_lst)-1: raise Exception(\"Setting inputs are wrong!\")\n",
    "    \n",
    "    N_settings = max((len_lst))\n",
    "    setting_lst = []\n",
    "    for lst in [distro_lst, datasize_lst, stepsize_lst]:\n",
    "        if len(lst)==1: \n",
    "            lst = lst*N_settings\n",
    "        setting_lst.append(lst)\n",
    "        \n",
    "    changed_setting = None\n",
    "    if len(distro_lst)>1:\n",
    "        changed_setting = 'distro'\n",
    "    elif len(datasize_lst)>1:\n",
    "        changed_setting = 'data_size'\n",
    "    elif len(stepsize_lst)>1:\n",
    "        changed_setting = 'step_size'\n",
    "    return np.asarray(setting_lst).T, changed_setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_dt(distro, datasize):\n",
    "#     return np.ones(size)\n",
    "    if distro == 'gau_1':\n",
    "        return np.random.normal(2, 18, datasize)\n",
    "    elif distro == 'gau_2':\n",
    "        return np.random.normal(0, 0.001, datasize)\n",
    "    elif distro == 'mix':\n",
    "        # mean: -1.3\n",
    "        # std: 30.779035604224564\n",
    "        # var: 947.3490327261234\n",
    "        mix_lst = np.zeros(datasize)\n",
    "        sizes = np.array([0.3, 0.2, 0.1, 0.15, 0.25])\n",
    "        mixtures = [(2,7), (0,0.7), (36, 26), (5,77), (-77,7)]\n",
    "        acc_sizes = [sum(sizes[:i+1]) for i in range(len(sizes))]\n",
    "\n",
    "        for d_idx in range(datasize):\n",
    "            rdn = np.random.uniform(0,1)\n",
    "            mix_id = 0\n",
    "            for m_id in acc_sizes:\n",
    "                if rdn > m_id:\n",
    "                    mix_id += 1\n",
    "                else:break\n",
    "            data_point = np.random.normal(mixtures[mix_id][0], mixtures[mix_id][1])\n",
    "            mix_lst[d_idx] = data_point\n",
    "        return mix_lst\n",
    "    elif distro == 'exp':\n",
    "        return np.random.exponential(scale=1, size=datasize)*6.5 - 20\n",
    "    else: raise Exception(\"distribution doesn't work!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(distro, datasize, g_test=False):\n",
    "    if g_test:\n",
    "        dataset = np.zeros((N_g, datasize))\n",
    "        for i in range(N_g):\n",
    "            dataset[i] = get_one_dt(distro, datasize)\n",
    "    else:\n",
    "        dataset = get_one_dt(distro, datasize)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_true(distro, tau_lst):\n",
    "    if tau_lst == tau_vals:\n",
    "        if distro=='gau_1':\n",
    "            return np.asarray([-21.06792817980280840537, \n",
    "                              -7.43920922874473411269,\n",
    "                              2,\n",
    "                              25.06792817980280840537,\n",
    "                              43.87426173273513981594])\n",
    "        elif distro=='gau_2':\n",
    "            return np.asarray([-0.001281551565544600466965,\n",
    "                              -5.244005127080407840383E-4,\n",
    "                              0,\n",
    "                              0.001281551565544600466965,\n",
    "                              0.002326347874040841100886])\n",
    "        elif distro=='mix':\n",
    "            # sampled from 100000000 datapoints\n",
    "            return np.asarray([-80.28496182,\n",
    "                               -29.02324254,\n",
    "                               -0.36011575,\n",
    "                               36.69268923,\n",
    "                               120.7676231])\n",
    "        elif distro=='exp':\n",
    "            return np.asarray([0.1053605156578263012275,\n",
    "                              0.3566749439387323789126,\n",
    "                              0.6931471805599453094172,\n",
    "                              2.302585092994045684018,\n",
    "                              4.605170185988091368036])*6.5 - 20\n",
    "    raise Exception('tau_lst should be tau_vals')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_batch(dataset, tau_lst):\n",
    "    if len(dataset.shape) != 1:\n",
    "        raise Exception('Dataset for q_batch calculation of wrong shape: ' + str(dataset.shape))\n",
    "        \n",
    "    q_batch = np.zeros(len(tau_lst))\n",
    "    for i, tau in enumerate(tau_lst):\n",
    "        q_batch[i] = np.percentile(dataset, tau*100)\n",
    "    return q_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_batches(dataset, tau_lst):\n",
    "    # g_test = False\n",
    "    if len(dataset.shape) == 1: \n",
    "        return get_q_batch(dataset, tau_lst)\n",
    "    else:\n",
    "        q_batches = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "        for i in range(q_batches.shape[0]):\n",
    "            q_batches[i] = get_q_batch(dataset[i], tau_lst)\n",
    "    return q_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stepsize(k, stepsize, length):\n",
    "    if stepsize=='const':\n",
    "        return 1 * np.ones(length)\n",
    "    elif stepsize=='2_div_sqrt_k':\n",
    "        return 2/math.sqrt(k)* np.ones(length)\n",
    "    elif stepsize=='0.002_div_sqrt_k':\n",
    "        return 0.002/math.sqrt(k) * np.ones(length)\n",
    "    raise Exception('stepsize parameter is wrong')\n",
    "    \n",
    "    \n",
    "# def set_stepsize(k, stepsize):\n",
    "#     if stepsize=='const':\n",
    "#         return 1\n",
    "#     elif stepsize=='2_div_sqrt_k':\n",
    "#         return 2/math.sqrt(k)\n",
    "#     elif stepsize=='0.002_div_sqrt_k':\n",
    "#         return 0.002/math.sqrt(k)\n",
    "#     raise Exception('stepsize parameter is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procs(dataset, step_size, tau_lst):\n",
    "    update_size = 200\n",
    "    proc = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "    q_pre, q_arr = np.zeros(len(tau_lst)), np.zeros(len(tau_lst))\n",
    "    alpha_adaptation = np.ones(len(tau_lst))\n",
    "\n",
    "    for k, x in enumerate(dataset):          \n",
    "        if k % update_size == 0 and k >0:\n",
    "#             print (k,q_arr-q_pre)\n",
    "            update_var = update_stepsize(alpha_arr, q_arr-q_pre, step_size, update_size)\n",
    "#             print ('update_var', update_var)\n",
    "            alpha_adaptation = alpha_adaptation * update_var\n",
    "#             print ('alpha_adaptation', alpha_adaptation)\n",
    "            q_pre = [i for i in q_arr]\n",
    "        if step_size != 'frugal': \n",
    "            alpha_arr = set_stepsize(k+1, step_size, len(tau_lst))* alpha_adaptation\n",
    "#             if k % update_size == 0: print('alpha_arr', alpha_arr)\n",
    "        for i, q in enumerate(q_arr):\n",
    "            tau = tau_lst[i]\n",
    "            alpha = alpha_arr[i]\n",
    "            if step_size != 'frugal':\n",
    "                q = sgd(q, x, tau, alpha)\n",
    "            else: \n",
    "                q = frugal(q, x, tau)\n",
    "            q_arr[i] = q\n",
    "        proc[k] = q_arr\n",
    "#     print (alpha_arr)\n",
    "    return proc.T\n",
    "   \n",
    "# def set_stepsize(idx, step_size, len_arr):\n",
    "#     return np.ones(len_arr)*10\n",
    "\n",
    "\n",
    "# def update_stepsize(alpha_arr, diff, step_size, update_size):\n",
    "#     update_var = np.ones(len(diff))\n",
    "#     for i, a in enumerate(alpha_arr):\n",
    "#         d = diff[i]\n",
    "#         if a * update_size * 0.35 < abs(d): update_var[i] = 2\n",
    "#         elif a * update_size * 0.05 > abs(d): update_var[i] = 1/2\n",
    "# #     print ('step_size', update_var)\n",
    "#     return update_var\n",
    "\n",
    "def update_stepsize(alpha_arr, diff, step_size, update_size):\n",
    "    update_var = np.ones(len(diff))\n",
    "    for i, a in enumerate(alpha_arr):\n",
    "        d = diff[i]\n",
    "        if a * update_size * 0.25 < abs(d): update_var[i] = 2\n",
    "        elif a * update_size * 0.02 > abs(d): update_var[i] = 1/2\n",
    "#     print ('step_size', update_var)\n",
    "    return update_var\n",
    "    \n",
    "def sgd(q, x, tau, alpha):\n",
    "    if x > q:\n",
    "        q = q + alpha*tau\n",
    "    else:\n",
    "        q = q - alpha*(1-tau)  \n",
    "    return q\n",
    "    \n",
    "def frugal(q, x, tau):\n",
    "    rdn = np.random.uniform()\n",
    "    if x > q and rdn > 1-tau:\n",
    "        q += 1\n",
    "    elif x < q and rdn > tau:\n",
    "        q -= 1\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_procs(dataset, step_size, tau_lst):\n",
    "#     if len(dataset.shape)!= 1: \n",
    "#         raise Exception('Dataset for get_procs() of wrong shape:' + str(dataset.shape)+ ', should be 1d array')\n",
    "        \n",
    "#     procs = np.zeros((len(tau_lst), dataset.shape[0]))\n",
    "#     for idx, tau in enumerate(tau_lst):\n",
    "#         q = 0\n",
    "#         q_sgd_proc = procs[idx]\n",
    "#         # change stepsize\n",
    "#         if step_size != 'frugal':\n",
    "#             for k, x in enumerate(dataset):\n",
    "# #                 if idx==1: print (k, ':', q)\n",
    "#                 alpha = set_stepsize(k+1, step_size)\n",
    "#                 if x > q:\n",
    "#                     q = q + alpha*tau\n",
    "#                 else:\n",
    "#                     q = q - alpha*(1-tau)\n",
    "#                 q_sgd_proc[k] = q\n",
    "        \n",
    "#         # frugal\n",
    "#         else:\n",
    "#             rdn_lst = np.random.uniform(0,1, dataset.shape[0])\n",
    "#             for k, x in enumerate(dataset):\n",
    "#                 rdn = rdn_lst[k]\n",
    "#                 if x > q and rdn > 1-tau:\n",
    "#                     q += 1\n",
    "#                 elif x < q and rdn > tau:\n",
    "#                     q -= 1\n",
    "#                 q_sgd_proc[k] = q\n",
    "#     return procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(procs):\n",
    "    if len(procs.shape)!=2:raise Exception('Procs of wrong shape:' + str(procs.shape)+ ', should be 2d array')\n",
    "    return procs[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_ests(dataset, step_size, tau_lst):\n",
    "\n",
    "    if len(dataset.shape)>2:\n",
    "        raise Exception('Dataset for q_est calculation of wrong shape:' + str(dataset.shape)+ ', should be 1d or 2d array')\n",
    "    if len(dataset.shape)==1:\n",
    "        procs = get_procs(dataset, step_size, tau_lst)\n",
    "        res = get_res(procs)\n",
    "    else:\n",
    "        res = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "        procs = np.zeros((dataset.shape[0], len(tau_lst), dataset.shape[1]))\n",
    "        for idx, dt in enumerate(dataset):\n",
    "            procs[idx] = get_procs(dt, step_size, tau_lst)\n",
    "            res[idx] = get_res(procs[idx])\n",
    "    return res, procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_dataset('gau_1', 1000, g_test=True) * 50 - 200\n",
    "# print(dataset.shape)\n",
    "\n",
    "# # proc1 = get_procs(dataset, 'const', tau_vals)\n",
    "# ## res1 = get_res(proc1)\n",
    "# # proc2 = get_procs(dataset, 'frugal', tau_vals)\n",
    "# # plt.plot(proc1.T)ad\n",
    "# # plt.plot(proc2.T)\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# res, proc = get_q_ests(dataset, 'const', tau_vals)\n",
    "# print(res)\n",
    "# print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_e(true, batches, est):\n",
    "    upper = est - batches\n",
    "    bottom = true - batches\n",
    "    return (upper/bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, filename, setting=None):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        if setting is not None: outfile.write('# Setting: {0}\\n'.format(setting))\n",
    "        if len(data.shape) == 1: data = data.reshape(-1, 1)\n",
    "        outfile.write('# Array shape: {0}\\n \\n'.format(data.shape))\n",
    "\n",
    "        for data_slice in data:\n",
    "            np.savetxt(outfile, data_slice, fmt='%-15.8g')\n",
    "            outfile.write('\\n')\n",
    "\n",
    "\n",
    "def write_data_overview(category, setting, tau_lst, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(\"Tested on \"+category+\": \"+str(setting)+\"\\n\") \n",
    "        f.write(str(tau_lst))\n",
    "    \n",
    "# write_data_overview('ca', 'se', tau_vals, \"try.txt\")\n",
    "    \n",
    "def save_data(foldername, file_name, tau_lst, data_dict):\n",
    "    print (\"save data folder name\", foldername)\n",
    "    pathlib.Path(foldername).mkdir(parents=True, exist_ok=True) \n",
    "    category, setting = file_name[0], file_name[1]    \n",
    "    write_data_overview(category, setting, tau_lst, foldername+str(setting)+\"_\"+\"overview.txt\")\n",
    "\n",
    "    for data_name in data_dict:\n",
    "        print (foldername+str(setting)+\"_\"+data_name+'.txt')\n",
    "        write_data(data_dict[data_name], foldername+str(setting)+\"_\"+data_name+'.txt')\n",
    "        \n",
    "    return\n",
    "\n",
    "# save_data(np.random.uniform(0, 1, 100), 'Experiment_results/Adaptive_stepsize/distro/mix_overview.txt')\n",
    "# save_data('', ('C', 'S'), tau_vals, {'dataset': np.reshape(np.random.uniform(0, 4, 100), (2, 5, 10))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(changed_setting, distro, datasize, stepsize, s_test):\n",
    "#     print(changed_setting)\n",
    "#     if s_test:\n",
    "#         return ('Shuffle', True)\n",
    "    if changed_setting=='distro':\n",
    "        return ('Distribution', distro)\n",
    "    elif changed_setting=='data_size':\n",
    "        return ('Data size', datasize)\n",
    "    elif changed_setting=='step_size':\n",
    "        return ('Step size', stepsize)\n",
    "    else: raise Exception ('Cannot get file name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_sgd_compare(folder_name, distro_lst, datasize_lst, stepsize_lst, \n",
    "                         g_test=False, s_test=False, tau_lst=tau_vals, \n",
    "                        ):\n",
    "    \n",
    "    if g_test and s_test: raise Exception(\"g_test and s_test can't both be true\")\n",
    "    \n",
    "    # generate different settings\n",
    "    setting_lst, changed_setting = get_settings(distro_lst, datasize_lst, stepsize_lst,)\n",
    "    print (setting_lst)\n",
    "    # if only stepsize changes, generate dataset and q_batches\n",
    "    dataset, q_batches = 0, 0\n",
    "    if changed_setting=='step_size':\n",
    "        dataset = get_dataset(distro_lst[0], datasize_lst[0], g_test)\n",
    "        q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "    # for each setting = [distro, datasize, stepsize]\n",
    "    for idx, setting in enumerate(setting_lst):\n",
    "        \n",
    "        # generate all the data\n",
    "        distro, datasize, stepsize = setting[0], int(setting[1]), setting[2]\n",
    "        q_true = get_q_true(distro, tau_lst)\n",
    "        if changed_setting != 'step_size':\n",
    "            dataset = get_dataset(distro, datasize, g_test)\n",
    "            q_batches = get_q_batches(dataset, tau_lst)\n",
    "        if s_test:\n",
    "            shuffled_dt = np.zeros((N_s, datasize))\n",
    "            for i in range(N_s):\n",
    "                np.random.shuffle(dataset)\n",
    "                shuffled_dt[i] = dataset\n",
    "            dataset = shuffled_dt\n",
    "        q_est_res, q_est_proc = get_q_ests(dataset, stepsize, tau_lst)\n",
    "        E = get_normalized_e(q_true, q_batches, q_est_res)\n",
    "        \n",
    "        data_dict = {\n",
    "            'q_true': q_true,\n",
    "            'q_batches': q_batches,\n",
    "            'q_est_res': q_est_res,\n",
    "            'q_est_proc': q_est_proc,\n",
    "            'E': E\n",
    "        }\n",
    "#         print(E)\n",
    "#         # generate charts and tables?\n",
    "        file_name = get_file_name(changed_setting, distro, datasize, stepsize, s_test)\n",
    "        save_data(folder_name, file_name, tau_lst, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_lst = ['data_size']        \n",
    "\n",
    "def all_sgd_comparisons(sgd_lst):\n",
    "    for t in sgd_lst:\n",
    "        print (t)\n",
    "        folder_name = \"Experiment_results/Adaptive_stepsize/\"+t+\"/\"\n",
    "        if t=='distro':\n",
    "            quantile_sgd_compare(folder_name, distros, [1000], ['const'], True)\n",
    "        elif t=='data_size':\n",
    "            quantile_sgd_compare(folder_name, ['gau_2'], [1000, 10000], ['const'], True)\n",
    "        elif t=='step_size':\n",
    "            quantile_sgd_compare(folder_name, ['gau_1'], [1000], stepsizes, True)\n",
    "        elif t=='data_sequence':\n",
    "            quantile_sgd_compare(folder_name, ['gau_1', 'gau_1'], [1000], ['const'], False, True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size\n",
      "[['gau_2' '1000' 'const']\n",
      " ['gau_2' '10000' 'const']]\n",
      "save data folder name Experiment_results/Adaptive_stepsize/data_size/\n",
      "Experiment_results/Adaptive_stepsize/data_size/1000_q_true.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/1000_q_batches.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/1000_q_est_res.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/1000_q_est_proc.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/1000_E.txt\n",
      "save data folder name Experiment_results/Adaptive_stepsize/data_size/\n",
      "Experiment_results/Adaptive_stepsize/data_size/10000_q_true.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/10000_q_batches.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/10000_q_est_res.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/10000_q_est_proc.txt\n",
      "Experiment_results/Adaptive_stepsize/data_size/10000_E.txt\n"
     ]
    }
   ],
   "source": [
    "# Run all functions\n",
    "all_sgd_comparisons(sgd_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sgd_frugal_compare(distro_lst, datasize, tau_lst=tau_vals):\n",
    "#     #distro changes, use the biggest datasize, do not shuffle\n",
    "#     for distro in distro_lst:\n",
    "#         q_true = get_q_true(distro, tau_lst)\n",
    "#         dataset = get_dataset(distro, datasize, False)\n",
    "#         q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "#         sgd_res, sgd_proc = get_q_ests(dataset, 'const', tau_lst)\n",
    "        \n",
    "#         N_frugal = 20\n",
    "#         frugal_res = np.zeros((N_frugal, len(tau_lst)))\n",
    "#         frugal_proc = np.zeros((N_frugal, len(tau_lst), datasize))\n",
    "#         for i in range(N_frugal):\n",
    "#             frugal_res[i], frugal_proc[i] = get_q_ests(dataset, 'frugal', tau_lst)\n",
    "        \n",
    "#         ax_name = 'Tested on '+distro+' distritbution with '+str(datasize)+' data points'\n",
    "#         fig, lgd = plot_procs(ax_name, tau_vals, q_true, frugal_proc, sgd_proc)\n",
    "#         title = fig.suptitle('Quantile Estimation: Frugal vs SGD')\n",
    "\n",
    "#         fd = \"Experiment_results/Frugal_SGD/\"\n",
    "#         plt.savefig(fd+distro+'.png', bbox_extra_artists=(lgd, title), bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "# sgd_frugal_compare(distros, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "### Always have $q_k = x$ for each x in the data stream\n",
    "\n",
    "When $x - q_k > 0$, we have $l(q_k) = \\tau(x-q_k)$:\n",
    "\\begin{align}\n",
    "q_{k+1} & = q_k - \\frac{l(q_k)}{l'(q_k)} \\\\\n",
    "        & = q_k - \\frac{\\tau(x-q_k)}{-\\tau} \\\\\n",
    "        & = q_k - (- x + q_k) \\\\\n",
    "        & = x\n",
    "\\end{align}\n",
    "\n",
    "Same happens when $x - q_k < 0$\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
